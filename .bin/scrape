#!/usr/bin/env python
# scrape: Extract HTML elements using an XPath query or CSS3 selector. 
#
# Example usage: curl 'http://en.wikipedia.org/wiki/List_of_sovereign_states' -s \
# | scrape -be 'table.wikitable > tr > td > b > a'
#
# Dependencies: lxml and optionally cssselector
#
# Author: http://jeroenjanssens.com

import sys
import argparse
from lxml import etree

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('html', nargs='?', type=argparse.FileType('rb'), default=sys.stdin, help="HTML", metavar="HTML")
    parser.add_argument('-e', '--expression', default='*', help="XPath query or CSS3 selector")
    parser.add_argument('-t', '--text', action='store_true', default=False, help="Output text instead of HTML")
    parser.add_argument('-b', '--body', action='store_true', default=False, help="Enclose output with HTML and BODY tags")
    parser.add_argument('-d', '--delimiter', default=' ', help="Delimiter when output is text")
    args = parser.parse_args()

    if not args.expression.startswith('//'):
        from cssselect import GenericTranslator, SelectorError
        try:
            expression = GenericTranslator().css_to_xpath(args.expression)
        except SelectorError:
            parser.error('Invalid CSS selector')
    else:
        expression = args.expression

    html_parser = etree.HTMLParser(encoding='utf-8', recover=True)
    document = etree.parse(args.html, html_parser)

    if args.body:
        sys.stdout.write("<!DOCTYPE html>\n<html>\n<body>\n")

    for e in document.xpath(expression):
        try:
            text = etree.tostring(e)
            sys.stdout.write(text.encode('utf-8') + "\n")
            sys.stdout.flush()
        except IOError:
            pass

    if args.body:
        sys.stdout.write("</body>\n</html>\n")

if __name__ == "__main__":
    exit(main())
